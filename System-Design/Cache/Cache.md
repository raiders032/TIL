# 1 Cache

* 캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리에 두고 뒤 이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다
* 캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스 보다 훨씬 빠르다
* 별도의 캐시를 두면 성능이 개선될 뿐아니라 데이터베이스의 부하도 줄일 수 있다

<br>

# 2 캐시 전략

* 캐시 전략은 다양하며 캐시할 데이터의 종류, 크기, 액세스 패턴에 맞는 캐시 전략을 선택해야 한다

<br>

## 2.1 읽기 주도형 캐시 전략

* 읽기 주도형 캐시 전략(read-through caching strategy)
* 읽기 주도형 캐시 전략은 데이터 요청 시 캐시를 먼저 확인하는 방식입니다. 
* 요청된 데이터가 캐시에 존재하면, 캐시에서 데이터를 바로 반환합니다. 
* 만약 캐시에 데이터가 없다면, 데이터베이스에서 데이터를 검색하고, 이 데이터를 캐시에 저장한 후 클라이언트에 반환합니다. 
* 이 전략의 장점은 애플리케이션 데이터 접근 속도를 크게 향상시키는 것입니다. 
* 단점은 처음 데이터를 요청할 때 캐시 미스(cache miss)가 발생하면, 응답 시간이 느려질 수 있다는 점입니다.

<br>

**읽기 주도형 캐시 전략 예시**

1. 요청을 받은 웹 서버는 캐시의 응답이 저장되어 있는지 확인한다
2. 만일 저장되어 있다면 해당 데이터를 클라이언트에 반환한다
3. 없는 경우 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 뒤 클라이언트에 반환한다

<br>

## 2.2 쓰기 주도형 캐시 전략 (Write-Through Caching)

- 쓰기 주도형 캐시 전략에서는 데이터가 캐시와 데이터베이스에 동시에 쓰여집니다. 
- 애플리케이션에서 데이터를 업데이트하거나 새로운 데이터를 삽입할 때, 이 변경사항은 즉시 캐시에도 반영되고 데이터베이스에도 저장됩니다. 
- 이 방식의 주된 장점은 데이터 일관성을 유지하는 것이며, 캐시가 항상 최신 상태를 유지한다는 것입니다. 
- 그러나 이 전략은 쓰기 연산의 성능에 영향을 줄 수 있습니다.

<br>

## 2.3  쓰기 지연 캐시 전략 (Write-Behind Caching)

- 쓰기 지연 캐시 전략(또는 후쓰기 캐시 전략)은 데이터 변경사항을 먼저 캐시에 적용하고, 이후 지정된 시간이 지나거나 특정 조건을 만족할 때 데이터베이스에 비동기적으로 업데이트합니다. 
- 이 전략은 쓰기 연산의 성능을 향상시키지만, 데이터베이스와 캐시 사이의 일시적인 일관성 불일치를 초래할 수 있습니다. 따라서, 적절한 동기화 메커니즘이 필요합니다.

<br>

# 3 유의사항

캐시는 주로 갱신이 자주 일어나지 않고 참조가 빈번한 데이터에 적합합니다. 데이터를 휘발성 메모리에 저장하기 때문에, 중요한 데이터는 영구적인 데이터 저장소에 보관해야 합니다. 캐시에 저장된 데이터는 만료 정책에 따라 주기적으로 갱신되거나 삭제되어야 합니다.

<br>

## 3.1 휘발성

* 캐시는 데이터를 휘발성 메모리에 두므로 영속적으로 보관할 데이터는 캐시에 두는 것은 바람직하지 않다
* 중요한 데이터는 여전히 persistent data store에 저장해야 한다

<br>

## 3.2 만료 정책

* 캐시에 보관된 데이터의 만료 정책을 정해야한다
* 만료 기한이 없는 경우 데이터가 캐시를 가득 채운다
* 만료 기한이 너무 짧은 경우 데이터베이스를 더 많이 접근하게 될 것이다
* 만료 기한이 너무 긴 경우 캐시된 데이터가 원본과 차이가 날 경우가 많아진다 

<br>

## 3.3 일관성(consistency)

* 일관성이란 데이터 저장소의 원본가 캐시 내의 사본이 같은지의 여부를 의미한다
* 저장소의 데이터를 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 일관성이 깨질 수 있다

<br>

## 3.4 장애 대처

* 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure)이 되어버린다
* 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우 이 특정 지점을 `Single Point of Failure`라고 한다
* 결과적으로 `Single Point of Failure`를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산해야 한다

<br>

## 3.5 메모리 크기 설정

* 캐시 메모리 크기는 얼마나 크게 잡아야 할까?
* 캐시 메모리가 너무 작으면 액세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게 된다
* 이를 막을 방법으로 캐시 메모리를 과할당 하는 것이다
	* 이렇게 하면 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있다

<br>

## 3.6 데이터 방출 정책

* 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다
* 이것을 캐시 데이터 방출 정책이라고 한다
* 가장 널리 쓰이는 방식은 LRU로 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책이다
* LFU(Least Frequently Used): 사용된 빈도가 가장 낮은 데이터를 방출
* FIFO(First In First Out): 가장 먼저 캐시에 들어온 데이터를 방출

<br>

# 4 CDN(Content delivery network)

* CDN은 정적 콘텐츠를 전송하는 데 쓰이는 지리적으로 분산된 네트워크이다
* 이미지, 비디오, CSS, JavaScript 파일을 등을 캐시할 수 있다

<br>

## 4.1 CDN 동작과정

1. 사용자 A가 이미지 URL을 이용해 이미지에 접근한다
   * URL의 도메인은 CDN 서비스 사업자가 제공한 것
2. CDN 서버의 캐시에 해당 이미지가 없는 경우 서버는 원본 서버에 요청하여 이미지를 가져온다
   * 원본 서버는 웹 서버일 수도 있고 아마존 S3 같은 온라인 저장소일 수 있다
3. 원본 서버가 CDN 서버에게 이미지를 반환한다
   * 응답 헤더에 TTL 값이 명시되어 있다
   * TTL은 해당 데이터의 만료시간을 의미한다
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다
   * 이미지는 TTL에 명시된 시간까지 캐시된다
5. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리한다.

<br>

## 4.2 CDN 사용 시 고려사항

* CDN은 보통 third party에서 운영하므로 CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내게 된다. 따라서 자주 사용되지 않는 콘텐츠는 CDN에 캐싱하지 말자
* 적절한 만료시간을 설정해야 하는데 너무 길면 신선도가 떨어지고 너무 짧으면 원본 서버에 빈번히 접속해 성능상 좋지 않다
* CDN 자체가 죽을 경우 애플리케이션이 어떻게 동작해야 하는지 고려해야 한다
	* 가령 CDN이 응답하지 않을 경우 원본 서버로로 부터 직접 콘텐츠를 가져오도록 클라이언트를 구성한다

<br>

## 4.3 장점

* 정적 콘텐츠를 더이상 웹 서버에서 서비스하지 않으며 CDN을 통해 제공하여 더 나은 성능을 보장
* 캐시가 데이터베이스 부하를 줄여준다

<br>

관련자료

* [웹 서비스 캐시 똑똑하게 다루기](https://toss.tech/article/smart-web-service-cache)